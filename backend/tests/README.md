# Guide des Tests

Documentation pour exÃ©cuter et Ã©crire des tests dans OpenGristAI.

## ğŸš€ Quick Start

```bash
# Installer les dÃ©pendances
cd backend && pip install -r requirements.txt

# Lancer tous les tests
make test-backend

# Tests spÃ©cifiques
make test-unit          # Tests unitaires seulement
make test-integration   # Tests d'intÃ©gration
```

## ğŸ“ Structure

```
tests/
â”œâ”€â”€ conftest.py          # Fixtures partagÃ©es (mock_grist_service, etc.)
â”œâ”€â”€ unit/                # Tests unitaires (rapides, mocked)
â””â”€â”€ integration/         # Tests d'intÃ©gration (workflows complets)
```

## âš¡ Commandes Principales

```bash
# Via Makefile (recommandÃ©)
make test-backend       # Tous les tests mocked
make test-unit          # Tests unitaires
make test-integration   # Tests d'intÃ©gration
make test-coverage      # Avec rapport de couverture

# Directement avec pytest
pytest                              # Tous les tests
pytest -v                           # Verbose
pytest -m unit                      # Tests unitaires seulement
pytest tests/unit/test_tools.py     # Fichier spÃ©cifique
pytest --cov=app --cov-report=html  # Coverage
```

## ğŸ·ï¸ Types de Tests

| Marker | Description | Vitesse | Besoin API |
|--------|-------------|---------|------------|
| `@pytest.mark.unit` | Tests unitaires isolÃ©s | âš¡ TrÃ¨s rapide | âŒ Non |
| `@pytest.mark.integration` | Workflows complets (mocked) | ğŸƒ Rapide | âŒ Non |
| `@pytest.mark.requires_api` | Tests avec vraie API Grist | ğŸ¢ Lent | âœ… Oui |

## ğŸ”Œ Tests avec API RÃ©elle (Optionnel)

Pour tester avec une vraie connexion Grist :

```bash
# 1. Configuration
export GRIST_API_KEY="votre_clÃ©"
export GRIST_DOCUMENT_ID="votre_doc_id"

# 2. Lancer les tests
pytest -m requires_api
```

âš ï¸ **Attention** : CrÃ©e des donnÃ©es temporaires dans votre document

## ğŸ› ï¸ Fixtures Principales

DÃ©finies dans `conftest.py`, utilisables directement :

```python
@pytest.mark.unit
async def test_example(mock_grist_service, sample_tables):
    # mock_grist_service : Service Grist mockÃ©
    # sample_tables : DonnÃ©es de test prÃ©dÃ©finies
    tables = await mock_grist_service.get_tables()
    assert len(tables) == 3
```

**Fixtures disponibles** :
- `mock_grist_service` - Service Grist mockÃ© complet
- `sample_tables`, `sample_columns`, `sample_records` - DonnÃ©es de test
- `api_client` - Client FastAPI pour tests d'API

## ğŸ“ Ã‰crire un Nouveau Test

```python
import pytest

@pytest.mark.unit  # ou @pytest.mark.integration
@pytest.mark.asyncio
class TestMyFeature:
    async def test_my_function(self, mock_grist_service):
        """Test de ma fonctionnalitÃ©."""
        result = await my_function()
        assert result == expected
```

## ğŸ› Debugging

```bash
pytest -x          # Stop au premier Ã©chec
pytest --lf        # Relancer seulement les tests qui ont Ã©chouÃ©
pytest --pdb       # Debugger interactif
pytest -s          # Voir les prints
```

## ğŸ’¡ Bonnes Pratiques

- âœ… Utiliser les fixtures existantes du `conftest.py`
- âœ… Ajouter le bon marker (`@pytest.mark.unit` ou `integration`)
- âœ… Tests rapides par dÃ©faut (mocks)
- âŒ Ne pas hardcoder de credentials
- âŒ Ne pas crÃ©er de mocks custom inutiles

